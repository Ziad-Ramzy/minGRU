{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://arxiv.org/abs/2410.01201\n",
    "# were RNNs All We Needed\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import tiktoken\n",
    "import urllib.request\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/refs/heads/master/data/tinyshakespeare/input.txt'\n",
    "filename = 'shakespeare.txt'\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "docs = open(\"shakespeare.txt\", \"r\").read().splitlines()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11387\n"
     ]
    }
   ],
   "source": [
    "tokens= set(enc.encode(\" \".join(docs)))\n",
    "tokens_ids = [int(i) for i in tokens]\n",
    "Vocab = {}\n",
    "for i in tokens_ids:\n",
    "    token = enc.decode([i])\n",
    "    Vocab[token] = i\n",
    "vocab_size = len(Vocab)\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([978353, 64]), Y shape: torch.Size([978353])\n",
      "X shape: torch.Size([95053, 64]), Y shape: torch.Size([95053])\n"
     ]
    }
   ],
   "source": [
    "block_size = 64 # context length: how many tokens do we take to predict the next one?\n",
    "\n",
    "def build_dataset(docs):  \n",
    "    X, Y = [], []\n",
    "  \n",
    "    for doc in docs:\n",
    "        context = [0] * block_size\n",
    "        for token in doc:\n",
    "            ix = Vocab.get(token)\n",
    "            if ix is None:\n",
    "                continue  # skip token if it's not in the vocabulary\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]  # crop and append\n",
    "\n",
    "    X = torch.tensor(X, dtype=torch.long)\n",
    "    Y = torch.tensor(Y, dtype=torch.long)\n",
    "    print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "    return X, Y\n",
    "\n",
    "n = int(len(docs) * 0.9)\n",
    "Xtr, Ytr = build_dataset(docs[:n])\n",
    "Xte, Yte = build_dataset(docs[n:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500617\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "hidden_size = 256\n",
    "block_size = 64\n",
    "batch_size = 32\n",
    "g = torch.Generator().manual_seed(983245) # for reproducibility\n",
    "C = torch.randn((vocab_size, n_embd),                   generator=g)\n",
    "# Parameters for the first minGRU layer\n",
    "Zt1_W  = torch.randn((block_size * n_embd, hidden_size), generator=g) * (1)/((block_size * n_embd)**0.5)\n",
    "Zt1_B  = torch.randn (hidden_size                      , generator=g) * 0 \n",
    "Ht1_W  = torch.randn((block_size * n_embd, hidden_size), generator=g) * (1)/((block_size * n_embd)**0.5)\n",
    "Ht1_B  = torch.randn(hidden_size                       , generator=g) * 0\n",
    "h_prev = torch.zeros((batch_size, hidden_size))\n",
    "\n",
    "# Parameters for the second min GRU layer\n",
    "Zt2_W = torch.randn((hidden_size, hidden_size),         generator=g) * (1)/((hidden_size)**0.5) # input-to-gate\n",
    "Zt2_B = torch.randn(hidden_size,                        generator=g) * 0\n",
    "Ht2_W = torch.randn((hidden_size, hidden_size),         generator=g) * (1)/((hidden_size)**0.5) # input-to-candidate\n",
    "Ht2_B = torch.randn(hidden_size,                        generator=g) * 0\n",
    "W     = torch.randn((hidden_size, vocab_size),          generator=g) * 0.01\n",
    "B     = torch.randn(vocab_size) * 0\n",
    "\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.ones((1, hidden_size))\n",
    "bnbias = torch.zeros((1, hidden_size))\n",
    "bnmean_running = torch.zeros((1, hidden_size))\n",
    "bnstd_running = torch.ones((1, hidden_size))\n",
    "\n",
    "\n",
    "parameters = [C, Zt1_W, Zt1_B, Ht1_W, Ht1_B, Zt2_W, Zt2_B, Ht2_W, Ht2_B, W, B, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 14/50000 [00:00<12:19, 67.55 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 2.1301419734954834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 1011/50000 [00:16<12:44, 64.11 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000, Loss: 1.7428120374679565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|▍         | 2009/50000 [00:29<11:02, 72.46 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2000, Loss: 1.4959784746170044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|▌         | 3008/50000 [00:43<10:30, 74.56 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3000, Loss: 1.960930585861206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|▊         | 4008/50000 [00:56<10:25, 73.58 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4000, Loss: 2.287388324737549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|█         | 5017/50000 [01:10<09:47, 76.57 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5000, Loss: 2.3840837478637695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  12%|█▏        | 6009/50000 [01:24<09:18, 78.77 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6000, Loss: 2.0343244075775146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  14%|█▍        | 7014/50000 [01:38<10:11, 70.35 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7000, Loss: 2.069871187210083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  16%|█▌        | 8005/50000 [01:53<14:54, 46.97 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8000, Loss: 1.3308762311935425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  18%|█▊        | 9005/50000 [02:06<09:34, 71.32 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9000, Loss: 1.7264564037322998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|██        | 10008/50000 [02:19<09:29, 70.20 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10000, Loss: 2.6870265007019043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  22%|██▏       | 11008/50000 [02:36<11:11, 58.03 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11000, Loss: 1.5227341651916504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  24%|██▍       | 12014/50000 [02:51<08:13, 77.01 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12000, Loss: 1.8487526178359985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  26%|██▌       | 13008/50000 [03:05<08:08, 75.68 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13000, Loss: 2.2663402557373047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  28%|██▊       | 14011/50000 [03:21<09:56, 60.33 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14000, Loss: 1.3932157754898071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  30%|███       | 15015/50000 [03:36<07:42, 75.63 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15000, Loss: 1.6852589845657349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  32%|███▏      | 16011/50000 [03:49<07:37, 74.25 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16000, Loss: 1.726888656616211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  34%|███▍      | 17012/50000 [04:05<07:46, 70.67 steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17000, Loss: 1.9028089046478271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  35%|███▌      | 17527/50000 [04:13<07:50, 69.04 steps/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m H2_t \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m Zt2) \u001b[38;5;241m*\u001b[39m H1_t \u001b[38;5;241m+\u001b[39m Zt2 \u001b[38;5;241m*\u001b[39m Htilde2\n\u001b[0;32m     28\u001b[0m outputs \u001b[38;5;241m=\u001b[39m H2_t \u001b[38;5;241m@\u001b[39m W \u001b[38;5;241m+\u001b[39m B \n\u001b[1;32m---> 29\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[0;32m     31\u001b[0m     p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ziad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ziad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ziad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ziad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_steps = 50000\n",
    "lossi = []\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# x_t: (batch_size, input_size)\n",
    "# h_prev: (batch_size, hidden_size)\n",
    "for step in tqdm(range(max_steps), desc='Training Progress', unit=' steps'):\n",
    "    minibatch = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[minibatch], Ytr[minibatch]\n",
    "    emb = C[Xb]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    Ztpreact = embcat @ Zt1_W + Zt1_B\n",
    "    Htilde = embcat @ Ht1_W + Ht1_B \n",
    "\n",
    "    bnmeani = Ztpreact.mean(0, keepdim=True)\n",
    "    bnstdi = Ztpreact.std(0, keepdim=True)\n",
    "    Ztpreact = bngain * (Ztpreact - bnmeani) / bnstdi + bnbias\n",
    "    with torch.no_grad():\n",
    "        bnmean_running = 0.999 * bnmean_running + 0.001 * bnmeani\n",
    "        bnstd_running = 0.999 * bnstd_running + 0.001 * bnstdi \n",
    "    Zt =  torch.sigmoid(Ztpreact)\n",
    "\n",
    "    H1_t = (1-Zt) * h_prev + Zt * Htilde # first hidden state\n",
    "    # Suppose H1_t is the output from the first minGRU layer\n",
    "    Zt2 = torch.sigmoid(H1_t @ Zt2_W + Zt2_B)\n",
    "    Htilde2 = H1_t @ Ht2_W + Ht2_B\n",
    "    H2_t = (1 - Zt2) * H1_t + Zt2 * Htilde2\n",
    "    outputs = H2_t @ W + B \n",
    "    loss = loss_fn(outputs.view(-1, vocab_size), Yb)\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    lr = 0.1 if step < 30000 else 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        tqdm.write(f'Step {step}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
